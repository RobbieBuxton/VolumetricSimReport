\section{Build System}

The build system plays a crucial role in compiling the simulator and rendering system, as well as in running the user study. Our simulator is a complex system that requires the compilation of C++, CUDA, and Python code, the management of large machine learning models, object files for rendering, and the handling of components such as camera drivers.\\

Portability is essential to ensure that the user study can be conducted on various systems. Given the author's previous experiences with graphical and hardware-dependent research projects, getting a project to build consistently on different machines is often a significant challenge.\\

One of the key goals of this project was to make the system as easy to build and run as possible on a variety of machines. This was important to ensure that the system could be used by other researchers in the future. To address these challenges, we chose to use Nix for our build system due to its declarative nature and ease of dependency management, including the ability to modify packages globally using overlays.

\subsection{Overview}

The build system provides two main sets of functionalities to the user. 

Firstly, it offers the Nix package \texttt{volumetricSim-0.0.1}, which serves as an automated set of instructions for compiling the simulator and its dependencies into a shared library (\texttt{libvolsim.so}) from scratch. Secondly, it provides a set of development environments designed for running the user study and for developing the Volumetric Simulator using Visual Studio Code (VSCode).

Both of these functionalities are accessible through the \texttt{nix flake} interface, as demonstrated in Listing~\ref{list:main-nix-flake}.
\codeBoxFile[label={list:main-nix-flake}]{shell}{./implementation/code/flake-show.sh}{Terminal}


\subsection{VolumetricSim Package}

You can build our simulator as a shared library using the following one-liner command from inside the main repository, as shown in Listing~\ref{list:nix-build}:
\codeBoxFile[label={list:nix-build}]{shell}{./implementation/code/nix-build.sh}{Terminal}

Alternatively, if you do not want to clone the repository, you can build the simulator without cloning it by taking advantage of Nix's ability to build from GitHub, as demonstrated in Listing~\ref{list:nix-build-remote}.
\codeBoxFile[label={list:nix-build-remote}]{shell}{./implementation/code/nix-build-remote.sh}{Terminal}

Although these may appear to be simple commands, they perform a significant amount of work behind the scenes. Firstly, they fetch all the dependencies required to build the simulator from source (or a public binary cache). You do not need to have any of these dependencies installed on your system, as Nix will manage all of this for you.

Our packages configure the following components:
\begin{enumerate}
	\item \textbf{CUDA:} Since we use the CUDA parallel computing platform \cite{4541126} in our simulator, we need to build the CUDA toolkit. Fortunately, Nix allows for a more fine-grained approach, enabling you to build only the components you need. We utilize the CUDA Deep Neural Network library (cuDNN), CUDA Basic Linear Algebra Subprograms library (cuBLAS), CUDA Random Number Generation library (cuRAND), and CUDA Dense Linear Solver library (cuSOLVER), along with the necessary libraries to interact with them. We override and recompile OpenCV and Dlib to be CUDA-enabled.

	\item \textbf{MKL:} We use the Intel Math Kernel Library (MKL) \cite{Wang2014} for some of our linear algebra operations, as it is significantly faster than the default BLAS library. We override and recompile OpenCV and Dlib to use the MKL BLAS libraries.

	\item \textbf{Azure Kinect Sensor SDK:} We have created our own Nix package for the Azure Kinect SDK \cite{noauthor_microsoftazure-kinect-sensor-sdk_2024}, as it was not previously packaged. This package provides the necessary drivers and stubs for the Azure Kinect camera to function.

	\item \textbf{OpenGL:} We download and configure GLFW \cite{noauthor_glfwglfw_2024} (a lightweight OpenGL utility library) and GLAD \cite{herberth_dav1ddeglad_2024} (hardware-specific OpenGL drivers) for the programming interface used in rendering 2D and 3D vector graphics with OpenGL \cite{woo1999opengl}.

	\item \textbf{Tracking Models:} We download and configure Dlib \cite{dlib09} and MediaPipe \cite{lugaresi2019mediapipe}, which are machine learning libraries used for our tracking models. We also automatically download the two required models for Dlib from the internet (verified by hash). Additionally, we download and build OpenCV for image management.
\end{enumerate}

Once all the dependencies are built, the simulator is compiled in a sandbox environment before being copied into the Nix store as a package containing the shared library \texttt{libvolsim.so} and all files the simulator depends on (tracking models, OBJ files, shaders). This shared library can be accessed from the User Study CLI to run the simulation. An overview of the final package contents is provided in the Appendix.

\subsection{Development Environments}

To facilitate our user study, we have created a development environment that includes all the necessary dependencies, primarily Python libraries, required to run the user study. Our shell script will also set up an alias that enables you to run the study via a CLI easily, as shown in Listing~\ref{list:study}.

\codeBoxFile[label={list:study}]{shell}{./implementation/code/study.sh}{Terminal}

Additionally, we have developed a separate environment containing all the dependencies needed to run the analysis and fully reproduce the graphs and tables presented in this document. \\

Finally, there is a development environment designed to automatically launch and manage a local MongoDB database for storing the results of the user study. This environment includes GUI tools, such as MongoDB Compass, for viewing and editing the database. This can be activated by running the command shown in Listing~\ref{list:mongo}.

\codeBoxFile[label={list:mongo}]{shell}{./implementation/code/mongo.sh}{Terminal}

\subsection{Additional Efforts}

One significant drawback of using Nix is that if a package is not already available, you usually have to package it yourself. Fortunately, almost everything we required was already available in the Nix package repository (nixpkgs), but there were a few exceptions. Typically, if a package is not available, it is because it is either not widely used or it is challenging to package.

\subsubsection{Azure Kinect Package}

The first project we had to package was the Azure Kinect SDK. This was not available in nixpkgs, and the only official package was a poorly ported, outdated Ubuntu binary from Windows. To package it in Nix, we had to manually patch the rpaths (run-time search paths hard-coded in an executable file) and resolve build and driver issues. Microsoft officially stopped supporting the Azure Kinect in August 2023 \cite{noauthor_microsofts_nodate}, so we decided to package a fork of \texttt{https://github.com/microsoft/Azure-Kinect-Sensor-SDK} that addressed the build issues we encountered. This process was quite challenging and required about a week of work. We have not yet upstreamed this package to nixpkgs but hope to do so in the future; it is currently available for all to use on GitHub.

\subsubsection{Dlib Package}

The second project involved packaging Dlib. Although Dlib was available in nixpkgs, we discovered that CUDA support had been incorrectly implemented (the maintainer had simply toggled a CMake flag without actually adding CUDA support). We were able to implement this locally using overlays (a functional method for globally mapping changes to all packages in Nix). We submitted a pull request (PR) to nixpkgs to fix this issue for everyone. This task took much longer than expected, as we ended up resolving many other issues in the package that did not initially affect us. This effort required about a week of work.

\subsubsection{MediaPipe}

The last challenge we faced was with MediaPipe. MediaPipe is a machine learning library built with Bazel \cite{noauthor_bazelbuildbazel_2024}, a build system that, while supported in nixpkgs, is difficult to work with due to design conflicts with Nix. To integrate it into our C++ project, we had to convert MediaPipe into a shared library by first wrapping it in a C interface before packaging it in Nix. This task was particularly time-consuming and difficult, taking about a week of work.
